{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAW_POINTS = list(range(0, 17))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALIGN_POINTS = (LEFT_EYE_POINTS+RIGHT_EYE_POINTS+LEFT_BROW_POINTS+RIGHT_BROW_POINTS+MOUTH_POINTS+NOSE_POINTS)\n",
    "\n",
    "OVERLAY_POINTS = (LEFT_EYE_POINTS+RIGHT_EYE_POINTS+LEFT_BROW_POINTS+RIGHT_BROW_POINTS+NOSE_POINTS+MOUTH_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLIB_PATH = 'shape_predictor_68_face_landmarks.dat'\n",
    "FACE_CASCADE = 'cascades/haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(FACE_CASCADE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor(DLIB_PATH)\n",
    "detector = dlib.get_frontal_face_detector()  ##  returns a list of rectangles, each of which corresponding with a face in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TooManyFaces(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoFaces(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image, use_dlib):\n",
    "    '''\n",
    "    Returns a 68x2 element matrix, each row of which corresponding with the \n",
    "    x, y coordinates of a particular feature point in image.\n",
    "    '''\n",
    "    if use_dlib == True:\n",
    "        points = detector(image, 1)\n",
    "\n",
    "        if len(points) > 1:\n",
    "            raise TooManyFaces\n",
    "        if len(points) == 0:\n",
    "            raise NoFaces\n",
    "\n",
    "        return np.matrix([[t.x, t.y] for t in predictor(image, points[0]).parts()])\n",
    "\n",
    "    else:\n",
    "        points = face_cascade.detectMultiScale(image, 1.3, 5)\n",
    "        if len(points) > 1:\n",
    "            return 'error'\n",
    "        if len(points) == 0:\n",
    "            return 'error'\n",
    "        x, y, w, h = points[0]\n",
    "        area = dlib.rectangle(int(x), int(y), int(x+w), int(y+h))\n",
    "\n",
    "        return np.matrix([[t.x, t.y] for t in predictor(image, area).parts()])\t\t \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_landmarks(image, landmarks):\n",
    "    image = image.copy()\n",
    "    for i, point in enumerate(landmarks):\n",
    "        position = (point[0,0], point[0,1])\n",
    "        cv2.putText(image, str(i), (position), fontFace=cv2.FONT_ITALIC, fontScale=0.4, color=(0,0,0))\n",
    "        cv2.circle(image, position, 3, color=(0,255,0))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_hull(image, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(image, points, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_mask(image, landmarks):\n",
    "    '''\n",
    "    Generate a mask for the image and a landmark matrix\n",
    "    '''\n",
    "    image = np.zeros(image.shape[:2], dtype=np.float64)\n",
    "\n",
    "    for grp in OVERLAY_POINTS:\n",
    "        convex_hull(image, landmarks[grp], color=1)\n",
    "\n",
    "    image = np.array([image, image, image]).transpose((1,2,0))\n",
    "    image = (cv2.GaussianBlur(image, (11,11), 0) > 0) * 1.0\t\t\n",
    "    image = cv2.GaussianBlur(image, (11,11), 0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_points(p1, p2):\n",
    "    '''\n",
    "    Calculates the rotation portion using the Singular Value Decomposition and\n",
    "    Return the complete transformaton as an affine transformation matrix.\n",
    "    '''\n",
    "    p1 = p1.astype(np.float64)\n",
    "    p2 = p2.astype(np.float64)\n",
    "\n",
    "    t1 = np.mean(p1, axis=0)\n",
    "    t2 = np.mean(p2, axis=0)\n",
    "    p1 -= t1\n",
    "    p2 -= t2\n",
    "\n",
    "    s1 = np.std(p1)\n",
    "    s2 = np.std(p2)\n",
    "    p1 /= s1\n",
    "    p2 /= s2\n",
    "\n",
    "    U, S, V = np.linalg.svd(p1.T * p2)\n",
    "    R = (U * V).T\n",
    "\n",
    "    return np.vstack([np.hstack(((s2/s1)*R, t2.T - (s2/s1) * R * t1.T)), np.matrix([0., 0., 1.])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(image):\n",
    "    img = image\n",
    "    img = cv2.resize(img, None, fx=0.4, fy=0.4, interpolation=cv2.INTER_LINEAR)\n",
    "    img = cv2.resize(img, (img.shape[1]* 1, img.shape[0]*1))\n",
    "\n",
    "    landmarks = get_landmarks(img, dlib)\n",
    "\n",
    "    return img, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(image, M, shape):\n",
    "    '''\n",
    "    Maps the second image onto the first and return ithe same\n",
    "    '''\n",
    "    initial = np.zeros(shape, dtype=image.dtype)\n",
    "    cv2.warpAffine(image, M[:2], (shape[1], shape[0]), dst=initial, borderMode=cv2.BORDER_TRANSPARENT, flags=cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "    \n",
    "    return initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_colors(image1, image2, landmarks, blur_factor=0.6):\n",
    "    '''\n",
    "    Changes the colouring of image2 to match that of image1\n",
    "    '''\n",
    "\n",
    "    blurred = blur_factor * np.linalg.norm(np.mean(landmarks[LEFT_EYE_POINTS], axis=0) - np.mean(landmarks[RIGHT_EYE_POINTS], axis=0))\n",
    "    blurred = int(blurred)\n",
    "\n",
    "    if blurred % 2 == 0:\n",
    "        blurred += 1\n",
    "    image1_blur = cv2.GaussianBlur(image1, (blurred, blurred), 0)\n",
    "    image2_blur = cv2.GaussianBlur(image2, (blurred, blurred), 0)\n",
    "\n",
    "    image2_blur += (128 * (image1_blur <= 1.0)).astype(image2_blur.dtype)\n",
    "\n",
    "    return (image2.astype(np.float64) * image1_blur.astype(np.float64) / image2_blur.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapped(image1 , image2):\n",
    "    '''\n",
    "    Combines all function and outputs a swapped image\n",
    "    '''\n",
    "    check = get_landmarks(image1, False)\n",
    "    \n",
    "    if check == 'error':\n",
    "        print ('Too Many Faces(No pun intended')\n",
    "        return image1\n",
    "\n",
    "    image1, landmarks1 = image1, check\n",
    "    image2, landmarks2 = read_features(image2)\t\n",
    "\n",
    "    M = transform_points(landmarks1[ALIGN_POINTS], landmarks2[ALIGN_POINTS])\n",
    "    \n",
    "    mask = face_mask(image2, landmarks2)\n",
    "    warped_mask = warp_image(mask, M, image1.shape)\n",
    "    combined_mask = np.max([face_mask(image1, landmarks1), warped_mask], axis=0)\n",
    "\n",
    "    warped_image2 = warp_image(image2, M, image1.shape)\n",
    "    warped_image2_new = mix_colors(image1, warped_image2, landmarks1)\n",
    "\n",
    "    final_output = image1 * (1.0 - combined_mask) + warped_image2_new * combined_mask\n",
    "    cv2.imwrite(\"SwappedImage.jpg\", final_output)\n",
    "    o = cv2.imread(\"SwappedImage.jpg\")\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "image = cv2.imread('images/Trump.jpg')\n",
    "use_dlib = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    response, frame = capture.read()\n",
    "    frame = cv2.resize(frame, None, fx=0.75, fy=0.75, interpolation=cv2.INTER_LINEAR)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    cv2.imshow(\"YOU LOOK LIKE\", swapped(frame, image))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
