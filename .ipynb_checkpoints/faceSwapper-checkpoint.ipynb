{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAW_POINTS = list(range(0, 17))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALIGN_POINTS = (LEFT_EYE_POINTS+RIGHT_EYE_POINTS+LEFT_BROW_POINTS+RIGHT_BROW_POINTS+MOUTH_POINTS+NOSE_POINTS)\n",
    "\n",
    "OVERLAY_POINTS = (LEFT_EYE_POINTS+RIGHT_EYE_POINTS+LEFT_BROW_POINTS+RIGHT_BROW_POINTS+NOSE_POINTS+MOUTH_POINTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'shape_predictor_68_face_landmarks.dat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor(PATH)\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TooManyFaces(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoFaces(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image):\n",
    "    '''\n",
    "    Returns a 68x2 element matrix, each row of which corresponding with the \n",
    "    x, y coordinates of a particular feature point in image.\n",
    "    '''\n",
    "    points = detector(image, 1)\n",
    "\n",
    "    if len(points) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(points) == 0:\n",
    "        raise NoFaces\n",
    "\n",
    "    return np.matrix([[t.x, t.y] for t in predictor(image, points[0]).parts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_landmarks(image, landmarks):\n",
    "    image = image.copy()\n",
    "    for i, point in enumerate(landmarks):\n",
    "        position = (point[0,0], point[0,1])\n",
    "        cv2.putText(image, str(i), (position), fontFace=cv2.FONT_ITALIC, fontScale=0.4, color=(0,0,0))\n",
    "        cv2.circle(image, position, 3, color=(0,255,0))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_hull(image, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(image, points, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_mask(image, landmarks):\n",
    "    '''\n",
    "    Generate a mask for the image and a landmark matrix\n",
    "    '''\n",
    "    image = np.zeros(image.shape[:2], dtype=np.float64)\n",
    "\n",
    "    for grp in OVERLAY_POINTS:\n",
    "        convex_hull(image, landmarks[grp], color=1)\n",
    "\n",
    "    image = np.array([image, image, image]).transpose((1,2,0))\n",
    "    image = (cv2.GaussianBlur(image, (11,11), 0) > 0) * 1.0\t\t\n",
    "    image = cv2.GaussianBlur(image, (11,11), 0)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_points(p1, p2):\n",
    "    '''\n",
    "    Calculates the rotation portion using the Singular Value Decomposition and\n",
    "    Return the complete transformaton as an affine transformation matrix.\n",
    "    '''\n",
    "    p1 = p1.astype(np.float64)\n",
    "    p2 = p2.astype(np.float64)\n",
    "\n",
    "    t1 = np.mean(p1, axis=0)\n",
    "    t2 = np.mean(p2, axis=0)\n",
    "    p1 -= t1\n",
    "    p2 -= t2\n",
    "\n",
    "    s1 = np.std(p1)\n",
    "    s2 = np.std(p2)\n",
    "    p1 /= s1\n",
    "    p2 /= s2\n",
    "\n",
    "    U, S, V = np.linalg.svd(p1.T * p2)\n",
    "    R = (U * V).T\n",
    "\n",
    "    return np.vstack([np.hstack(((s2/s1)*R, t2.T - (s2/s1) * R * t1.T)), np.matrix([0., 0., 1.])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(image):\n",
    "    img = image\n",
    "    img = cv2.resize(img, None, fx=1, fy=1, interpolation=cv2.INTER_LINEAR)\n",
    "    img = cv2.resize(img, (img.shape[1]* 1, img.shape[0]*1))\n",
    "\n",
    "    landmarks = get_landmarks(img)\n",
    "\n",
    "    return img, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(image, M, shape):\n",
    "    '''\n",
    "    Maps the second image onto the first and return ithe same\n",
    "    '''\n",
    "    initial = np.zeros(shape, dtype=image.dtype)\n",
    "    cv2.warpAffine(image, M[:2], (shape[1], shape[0]), dst=initial, borderMode=cv2.BORDER_TRANSPARENT, flags=cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "    return initial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_colors(image1, image2, landmarks, blur_factor=0.6):\n",
    "    '''\n",
    "    Changes the colouring of image2 to match that of image1\n",
    "    '''\n",
    "\n",
    "    blurred = blur_factor * np.linalg.norm(np.mean(landmarks[LEFT_EYE_POINTS], axis=0) - np.mean(landmarks[RIGHT_EYE_POINTS], axis=0))\n",
    "    blurred = int(blurred)\n",
    "\n",
    "    if blurred % 2 == 0:\n",
    "        blurred += 1\n",
    "    image1_blur = cv2.GaussianBlur(image1, (blurred, blurred), 0)\n",
    "    image2_blur = cv2.GaussianBlur(image2, (blurred, blurred), 0)\n",
    "\n",
    "    image2_blur += (128 * (image1_blur <= 1.0)).astype(image2_blur.dtype)\n",
    "\n",
    "    return (image2.astype(np.float64) * image1_blur.astype(np.float64) / image2_blur.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapped(image1 , image2):\n",
    "    '''\n",
    "    Combines all function and outputs a swapped image\n",
    "    '''\n",
    "    image1, landmarks1 = read_features(image1)\n",
    "    image2, landmarks2 = read_features(image2)\t\n",
    "\n",
    "    M = transform_points(landmarks1[ALIGN_POINTS], landmarks2[ALIGN_POINTS])\n",
    "    \n",
    "    mask = face_mask(image2, landmarks2)\n",
    "    warped_mask = warp_image(mask, M, image1.shape)\n",
    "    combined_mask = np.max([face_mask(image1, landmarks1), warped_mask], axis=0)\n",
    "\n",
    "    warped_image2 = warp_image(image2, M, image1.shape)\n",
    "    warped_image2_new = mix_colors(image1, warped_image2, landmarks1)\n",
    "\n",
    "    final_output = image1 * (1.0 - combined_mask) + warped_image2_new * combined_mask\n",
    "    cv2.imwrite(\"SwappedImage2.jpg\", final_output) #this is the output file name\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('images/Hillary.jpg')\n",
    "image2 = cv2.imread('images/mr_robot.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarth\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "swapped_image = swapped(image1, image2)\n",
    "#cv2.imshow(\"Swapped 1\", swapped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Swapped\", swapped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
